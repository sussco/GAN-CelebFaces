{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import hsv_to_rgb\n",
    "import os\n",
    "import cv2\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_and_resize_64():\n",
    "    if not os.path.isdir(\"img_align_celeba_64\"):\n",
    "        os.mkdir(\"img_align_celeba_64\")\n",
    "    for i in range(1, 202599 + 1):\n",
    "        name = str(i).zfill(6) + \".jpg\"\n",
    "        img = cv2.imread(\"img_align_celeba/\" + name, 1)\n",
    "        img = cv2.resize(img[50:191,30:171], (64,64))\n",
    "        cv2.imwrite(\"img_align_celeba_64/\" + name, img)\n",
    "#crop_and_resize_64()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we will get the 100 000 first images and put them in a variable 178*218*3\n",
    "dataset_size = 50000 #202599\n",
    "\n",
    "        \n",
    "def get_batch(batch_size):\n",
    "        indexes = np.random.randint(1, dataset_size + 1, batch_size)\n",
    "        data = []\n",
    "        imgname = \"img_align_celeba_64/\"\n",
    "        for i in indexes:\n",
    "            #image = tf.read_file(imgname + str(i).zfill(6) + \".jpg\")\n",
    "            #image = tf.image.decode_jpeg(image, channels=3)\n",
    "            image = mpimg.imread(imgname + str(i).zfill(6) + \".jpg\")\n",
    "            # Normalizing & centering images\n",
    "            image = image - np.mean(image)\n",
    "            image = image / np.var(image)\n",
    "            data.append(image)\n",
    "        return np.array(data)\n",
    "\n",
    "def sample_Z(batch_size=50, n=128):\n",
    "        return np.random.uniform(-1., 1., size=[batch_size, n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_cnn(Z, fc_sizes=[110,200,300], output_dim=3, reuse=False, alpha=0.2, keep_prob=0.5,is_train=True):\n",
    "    \n",
    "    with tf.variable_scope(\"GAN/Generator_cnn\",reuse=reuse):      \n",
    "         # 1. Fully connnected\n",
    "        fc = tf.layers.dense(Z, 4*4*512, use_bias=False)\n",
    "        fc = tf.reshape(fc, (-1, 4, 4, 512))\n",
    "        bn0 = tf.layers.batch_normalization(fc, training=is_train)\n",
    "        relu0 = tf.nn.relu(bn0)\n",
    "        drop0 = tf.layers.dropout(relu0, keep_prob, training=is_train)\n",
    "        \n",
    "        # 2. Deconvolution \n",
    "        conv1 = tf.layers.conv2d_transpose(drop0, 256, 5, 2, 'same', use_bias=False)\n",
    "        bn1 = tf.layers.batch_normalization(conv1, training=is_train)\n",
    "        relu1 = tf.nn.relu(bn1)\n",
    "        drop1 = tf.layers.dropout(relu1, keep_prob, training=is_train)\n",
    "        \n",
    "        # 3. Deconvolution\n",
    "        conv2 = tf.layers.conv2d_transpose(drop1, 128, 5, 2, 'same', use_bias=False)\n",
    "        bn2 = tf.layers.batch_normalization(conv2, training=is_train)\n",
    "        relu2 = tf.nn.relu(bn2)\n",
    "        drop2 = tf.layers.dropout(relu2, keep_prob, training=is_train)\n",
    "        \n",
    "        # 4. Deconvolution\n",
    "        conv3 = tf.layers.conv2d_transpose(drop2, 64, 5, 2, 'same', use_bias=False)\n",
    "        bn3 = tf.layers.batch_normalization(conv3, training=is_train)\n",
    "        relu3 = tf.nn.relu(bn3)\n",
    "        drop3 = tf.layers.dropout(relu3, keep_prob, training=is_train)\n",
    "        \n",
    "        # 5. dense, Output layer\n",
    "        out = tf.layers.conv2d_transpose(drop3, output_dim, 5, 2, 'same')\n",
    "        logits = tf.tanh(out)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_cnn(X, fc_sizes=[110,300,200], reuse=False, alpha=0.2, keep_prob=0.5):\n",
    "    \n",
    "    with tf.variable_scope(\"GAN/Discriminator_cnn\",reuse=reuse):\n",
    "        # Input layer is 64x64x3\n",
    "        # Convolutional layer, 30x30x64\n",
    "        conv1 = tf.layers.conv2d(X, 64, 5, 2, padding='same', kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        lrelu1 = tf.maximum(alpha * conv1, conv1)\n",
    "        drop1 = tf.layers.dropout(lrelu1, keep_prob)\n",
    "        \n",
    "        # Strided convolutional layer, 13x13x128\n",
    "        conv2 = tf.layers.conv2d(drop1, 128, 5, 2, 'same', use_bias=False)\n",
    "        bn2 = tf.layers.batch_normalization(conv2)\n",
    "        lrelu2 = tf.maximum(alpha * bn2, bn2)\n",
    "        drop2 = tf.layers.dropout(lrelu2, keep_prob)\n",
    "        \n",
    "        # Strided convolutional layer, 5x5x256\n",
    "        conv3 = tf.layers.conv2d(drop2, 256, 5, 2, 'same', use_bias=False)\n",
    "        bn3 = tf.layers.batch_normalization(conv3)\n",
    "        lrelu3 = tf.maximum(alpha * bn3, bn3)\n",
    "        drop3 = tf.layers.dropout(lrelu3, keep_prob)\n",
    "        \n",
    "        # Strided convolutional layer, 1x1x512\n",
    "        conv4 = tf.layers.conv2d(drop3, 512, 5, 2, 'same', use_bias=False)\n",
    "        bn4 = tf.layers.batch_normalization(conv4)\n",
    "        lrelu4 = tf.maximum(alpha * bn4, bn4)\n",
    "        drop4 = tf.layers.dropout(lrelu4, keep_prob)\n",
    "        \n",
    "        # fully connected\n",
    "        flat = tf.reshape(drop4, (-1, 512))\n",
    "        out0 = tf.layers.dense(flat, 1)\n",
    "        out = tf.nn.sigmoid(out0)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32,[None,64,64,3])\n",
    "#XX = tf.reshape(X, shape=(tf.shape(X)[0], 64*64*3))\n",
    "Z = tf.placeholder(tf.float32,[None,128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fake = generator_cnn(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_data_logits = discriminator_cnn(X)\n",
    "fake_data_logits = discriminator_cnn(X_fake, reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=true_data_logits,labels=tf.ones_like(true_data_logits)) + tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_data_logits,labels=tf.zeros_like(fake_data_logits)))\n",
    "#G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_data_logits,labels=tf.ones_like(fake_data_logits)))\n",
    "\n",
    "D_loss = -tf.reduce_mean(true_data_logits) + tf.reduce_mean(fake_data_logits)\n",
    "G_loss = -tf.reduce_mean(fake_data_logits)\n",
    "\n",
    "batch_size = 64\n",
    "lambda_gp = 10.0\n",
    "# Gradient Penalty\n",
    "epsilon = tf.random_uniform(shape=[batch_size,1, 1, 1], minval=0.,maxval=1.)\n",
    "X_hat =  X + epsilon * (X_fake - X) #epsilon * X + (1-epsilon) * X_fake\n",
    "D_X_hat = discriminator_cnn(X_hat, reuse=True)\n",
    "grad_D_X_hat = tf.gradients(D_X_hat, [X_hat])[0]\n",
    "reduction_indexes = [1]\n",
    "slopes = tf.sqrt(tf.reduce_sum(tf.square(grad_D_X_hat), reduction_indices=reduction_indexes))\n",
    "gradient_penalty = tf.reduce_mean((slopes - 1.) ** 2)\n",
    "D_loss += lambda_gp * gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,scope=\"GAN/Generator_cnn\")\n",
    "D_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,scope=\"GAN/Discriminator_cnn\")\n",
    "\n",
    "G_step = tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.5, beta2=0.9).minimize(G_loss,var_list = G_variables)\n",
    "D_step = tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.5, beta2=0.9).minimize(D_loss,var_list = D_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 0\t Discriminator loss: 9.9158\t Generator loss: -0.0111\n",
      "Iterations: 1\t Discriminator loss: 9.2233\t Generator loss: -0.8425\n",
      "Iterations: 2\t Discriminator loss: 10.1277\t Generator loss: -0.0785\n",
      "Iterations: 3\t Discriminator loss: 9.0887\t Generator loss: -0.7524\n",
      "Iterations: 4\t Discriminator loss: 10.0869\t Generator loss: -0.5682\n",
      "Iterations: 5\t Discriminator loss: 9.7963\t Generator loss: -0.0035\n",
      "Iterations: 6\t Discriminator loss: 9.0163\t Generator loss: -0.4121\n",
      "Iterations: 7\t Discriminator loss: 9.6834\t Generator loss: -0.2423\n",
      "Iterations: 8\t Discriminator loss: 9.3515\t Generator loss: -0.0568\n",
      "Iterations: 9\t Discriminator loss: 8.7046\t Generator loss: -0.9972\n",
      "Iterations: 10\t Discriminator loss: 9.9324\t Generator loss: -0.5882\n",
      "Iterations: 11\t Discriminator loss: 8.8170\t Generator loss: -0.0091\n",
      "Iterations: 12\t Discriminator loss: 8.8326\t Generator loss: -0.0830\n",
      "Iterations: 13\t Discriminator loss: 9.0735\t Generator loss: -0.2550\n",
      "Iterations: 14\t Discriminator loss: 9.2599\t Generator loss: -0.3220\n",
      "Iterations: 15\t Discriminator loss: 8.4489\t Generator loss: -0.1258\n",
      "Iterations: 16\t Discriminator loss: 8.4718\t Generator loss: -0.1282\n",
      "Iterations: 17\t Discriminator loss: 8.6153\t Generator loss: -0.9995\n",
      "Iterations: 18\t Discriminator loss: 9.6438\t Generator loss: nan\n",
      "Iterations: 19\t Discriminator loss: nan\t Generator loss: nan\n",
      "Iterations: 20\t Discriminator loss: nan\t Generator loss: nan\n",
      "Iterations: 21\t Discriminator loss: nan\t Generator loss: nan\n",
      "Iterations: 22\t Discriminator loss: nan\t Generator loss: nan\n",
      "Iterations: 23\t Discriminator loss: nan\t Generator loss: nan\n",
      "Iterations: 24\t Discriminator loss: nan\t Generator loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1dfbcd17828>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "tf.global_variables_initializer().run(session=sess)\n",
    "\n",
    "\n",
    "nd_steps = 10\n",
    "ng_steps = 10\n",
    "#dataset = get_data_normalized(1000)\n",
    "\n",
    "for i in range(25):\n",
    "    X_batch = get_batch(batch_size)\n",
    "    Z_batch = sample_Z(batch_size, 128)\n",
    "    _, dloss = sess.run([D_step, D_loss], feed_dict={X: X_batch, Z: Z_batch})\n",
    "    _, gloss = sess.run([G_step, G_loss], feed_dict={Z: Z_batch})\n",
    "\n",
    "    print(\"Iterations: %d\\t Discriminator loss: %.4f\\t Generator loss: %.4f\"%(i,dloss,gloss))\n",
    "\n",
    "Z_batch = sample_Z(1, 128)\n",
    "X_batch = get_batch(1)\n",
    "sess.run(X_fake, feed_dict={X: X_batch, Z: Z_batch})\n",
    "plt.imshow(tf.reshape((255*(X_fake+1)/2), shape=(64, 64,3)).eval(session=sess, feed_dict={X: X_batch, Z: Z_batch}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"GAN/Generator_cnn/conv2d_transpose_3/BiasAdd:0\", shape=(?, 64, 64, 3), dtype=float32)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Fetch argument None has invalid type <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-87860a7cbd2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mZ_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_Z\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mX_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG_fake_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mZ_batch\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG_fake_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mZ_batch\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\corty\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\corty\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1083\u001b[0m     \u001b[1;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[1;32m-> 1085\u001b[1;33m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[0;32m   1086\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\corty\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[0;32m    425\u001b[0m     \"\"\"\n\u001b[0;32m    426\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\corty\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[1;34m(fetch)\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfetch\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m       raise TypeError('Fetch argument %r has invalid type %r' % (fetch,\n\u001b[1;32m--> 242\u001b[1;33m                                                                  type(fetch)))\n\u001b[0m\u001b[0;32m    243\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m       \u001b[1;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Fetch argument None has invalid type <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "Z_batch = sample_Z(1, 128)\n",
    "X_batch = get_batch(1)\n",
    "sess.run(X_fake, feed_dict={X: X_batch, Z: Z_batch})\n",
    "plt.imshow(tf.reshape(X_fake, shape=(64, 64,3)).eval(session=sess, feed_dict={X: X_batch, Z: Z_batch}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'G_sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-aa90b0ae69c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mZ_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_Z\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mX_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mZ_batch\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mZ_batch\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'G_sample' is not defined"
     ]
    }
   ],
   "source": [
    "Z_batch = sample_Z(1, 128)\n",
    "X_batch = get_batch(1)\n",
    "sess.run(G_sample, feed_dict={X: X_batch, Z: Z_batch})\n",
    "plt.imshow(tf.reshape(G_sample, shape=(64, 64,3)).eval(session=sess, feed_dict={X: X_batch, Z: Z_batch}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'G_sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-aa90b0ae69c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mZ_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_Z\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mX_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mZ_batch\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mZ_batch\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'G_sample' is not defined"
     ]
    }
   ],
   "source": [
    "Z_batch = sample_Z(1, 128)\n",
    "X_batch = get_batch(1)\n",
    "sess.run(G_sample, feed_dict={X: X_batch, Z: Z_batch})\n",
    "plt.imshow(tf.reshape(G_sample, shape=(64, 64,3)).eval(session=sess, feed_dict={X: X_batch, Z: Z_batch}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
